{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "======\n",
      "Loading NuScenes tables for version v1.0-mini...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "911 instance,\n",
      "12 sensor,\n",
      "120 calibrated_sensor,\n",
      "31206 ego_pose,\n",
      "8 log,\n",
      "10 scene,\n",
      "404 sample,\n",
      "31206 sample_data,\n",
      "18538 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 0.467 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 0.1 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "import nuscenes.lidarseg\n",
    "from nuscenes.utils.data_classes import LidarPointCloud, RadarPointCloud, Box\n",
    "import utils_data_viewer\n",
    "from utils_data_viewer import view_scene_map, custom_draw_geometry, cam_vis, top_down, interactive_vis, visualize_lidar_in_img\n",
    "from utils_data_viewer import project_points_in_img, colorise_pcd, visualize_lidar_in_img_sweeps, visualize_radar_in_img_sweeps\n",
    "#Radar\n",
    "from utils_data_viewer import top_down_radar, interactive_vis_radar, radar_from_file, fuse_radars_in_ego, visualize_radar_in_img\n",
    "import utils_obj_det\n",
    "from utils_obj_det import get_radar_in_img, vis_obj_det_speed\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from scipy.spatial.transform import Rotation\n",
    "from pyquaternion import Quaternion\n",
    "import struct\n",
    "import matplotlib as plt\n",
    "\n",
    "import cv2\n",
    "import open3d as o3d\n",
    "\n",
    "\n",
    "nusc = NuScenes(version='v1.0-mini', dataroot='/data/sets/nuscenes', verbose=True)\n",
    "utils_data_viewer.nusc = nusc\n",
    "utils_obj_det.nusc = nusc\n",
    "\n",
    "#nusc.list_scenes()\n",
    "sc_id = 4\n",
    "\n",
    "scene = nusc.scene[sc_id]\n",
    "log = nusc.get('log', scene['log_token'])\n",
    "map = nusc.get('map', log['map_token'])\n",
    "map_file = os.path.join(nusc.dataroot, map['filename'])\n",
    "\n",
    "first_sample = nusc.get('sample', scene['first_sample_token'])\n",
    "last_sample = nusc.get('sample', scene['last_sample_token'])\n",
    "sample = first_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sample = nusc.get('sample', scene['first_sample_token'])\n",
    "last_sample = nusc.get('sample', scene['last_sample_token'])\n",
    "sample = first_sample\n",
    "cam = nusc.get('sample_data', sample['data']['CAM_FRONT'])\n",
    "cam_sensor = nusc.get('calibrated_sensor', cam['calibrated_sensor_token'])\n",
    "lidar = nusc.get('sample_data', first_sample['data']['LIDAR_TOP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cam_vis_sweep(scene, 'CAM_FRONT')\n",
    "#visualize_lidar_in_img_sweeps(scene, cam_channel='CAM_BACK')\n",
    "visualize_radar_in_img_sweeps(scene, cam_channel='CAM_FRONT')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc_ids = [0, 2, 3, 4, 6, 7, 8]\n",
    "# channels = ['CAM_FRONT', 'CAM_FRONT_LEFT', 'CAM_FRONT_RIGHT', 'CAM_BACK', 'CAM_BACK_LEFT', 'CAM_BACK_RIGHT']\n",
    "# for sc_i in sc_ids:\n",
    "#     scene = nusc.scene[sc_i]\n",
    "#     for c in channels:\n",
    "    #     cam_vis(scene, c, record=True)\n",
    "    #     visualize_lidar_in_img(scene, c, record=True)\n",
    "    #     visualize_radar_in_img(scene, c, record=True)\n",
    "    #     vis_obj_det_speed(scene, cam_channel=c)\n",
    "    # top_down(scene, record=True)\n",
    "    #top_down_radar(scene, record=True)\n",
    "    # interactive_vis(scene, record=True)\n",
    "    # colorise_pcd(scene, record=True)\n",
    "    # interactive_vis_radar(scene, record=True)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nusc.render_pointcloud_in_image(sample['token'], pointsensor_channel='LIDAR_TOP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lidar\n",
    "rec = False\n",
    "#view_scene_map(scene)\n",
    "#visualize_lidar_in_img(scene, cam_channel='CAM_FRONT')\n",
    "#colorise_pcd(scene, record=rec)\n",
    "#cam_vis(scene, \"CAM_BACK\")\n",
    "#interactive_vis(scene, record=rec)\n",
    "#top_down(scene, record=True)\n",
    "\n",
    "#Radar\n",
    "#interactive_vis_radar(scene, record=True)\n",
    "#interactive_vis_radar_sweeps(scene)\n",
    "#top_down_radar(scene, record=True)\n",
    "#visualize_radar_in_img(scene, cam_channel='CAM_BACK', record=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BACKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_channel = 'RADAR_FRONT'\n",
    "radar = nusc.get('sample_data', sample['data'][radar_channel])\n",
    "radar_file = os.path.join(nusc.dataroot, radar['filename'])\n",
    "pts, fields = radar_from_file(radar_file)\n",
    "radar_sensor = nusc.get('calibrated_sensor', radar['calibrated_sensor_token'])\n",
    "velocities = pts[8:9, :]  # Compensated velocity\n",
    "\n",
    "s, f = fuse_radars_in_ego(sample)\n",
    "s.shape\n",
    "\n",
    "velocities = np.vstack((velocities, np.zeros(pts.shape[1])))\n",
    "velocities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.expand_dims(pts, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End RADAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize_lidar_in_img(scene, cam_channel='CAM_FRONT')\n",
    "#colorise_pcd(scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show the map of the scene\n",
    "#view_scene_map(scene)\n",
    "#visualize_lidar_in_img(scene, cam_channel='CAM_FRONT')\n",
    "#colorise_pcd(scene)\n",
    "#cam_vis(scene, \"CAM_BACK\")\n",
    "interactive_vis(scene, record=True)\n",
    "#top_down(scene, record=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show front cam view through scene\n",
    "#cam_vis(scene, \"CAM_BACK\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Pointcloud LIDAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize with interactive view control\n",
    "#interactive_vis(scene, record=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize top down view only\n",
    "#top_down(scene, record=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuse colored pointcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sample = nusc.get('sample', scene['first_sample_token'])\n",
    "last_sample = nusc.get('sample', scene['last_sample_token'])\n",
    "sample = first_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sample = nusc.get('sample', scene['first_sample_token'])\n",
    "last_sample = nusc.get('sample', scene['last_sample_token'])\n",
    "sample = first_sample\n",
    "channels = ['CAM_FRONT', 'CAM_FRONT_LEFT', 'CAM_FRONT_RIGHT', 'CAM_BACK', 'CAM_BACK_LEFT', 'CAM_BACK_RIGHT']\n",
    "\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "#Visualize a video sequence of LIDAR data  \n",
    "\n",
    "#Render callback for non blocking visualization which allows smoother control of view\n",
    "#Define the callback here to simplify the transfer of variables samples, and pcd\n",
    "def render_callback(vis):\n",
    "    global sample, pcd, channels\n",
    "    cam_channel = 'CAM_FRONT_LEFT'\n",
    "    if sample['token'] == last_sample['token']:\n",
    "        return False\n",
    "\n",
    "    #Load next scan\n",
    "    #cam = nusc.get('sample_data', sample['data'][cam_channel])\n",
    "    #Load lidar scan\n",
    "    lidar = nusc.get('sample_data', sample['data']['LIDAR_TOP'])\n",
    "\n",
    "    #Merged points\n",
    "    pcd_points =np.empty((0, 3))\n",
    "    pcd_colors =np.empty((0, 3))\n",
    "    for channel in channels:\n",
    "        #Load next scan\n",
    "        cam = nusc.get('sample_data', sample['data'][channel])\n",
    "        points, color = project_points_in_img(cam, lidar)\n",
    "        pcd_points = np.append(pcd_points, points, axis=0)\n",
    "        pcd_colors = np.append(pcd_colors, color, axis=0)\n",
    "\n",
    "    #pcd_points, pcd_color = project_points_in_img(cam, lidar)\n",
    "    #####\n",
    "    print(\"FINAL POINTS: \", pcd_points.shape)\n",
    "    lidar_file = nusc.get_sample_data_path(lidar['token'])\n",
    "    scan = np.fromfile(lidar_file, dtype=np.float32).reshape(-1, 5) #x, y, z, intensity, Ring Index\n",
    "    points = scan[:, :3]\n",
    "    #print(\"ORIG Points: \", points.shape)\n",
    "    #print(\"Percentage: \", pcd_points.shape[0] / points.shape[0])\n",
    "    #####\n",
    "    #Update Geometry\n",
    "    if sample['token'] == first_sample['token']:\n",
    "        pcd.points = o3d.utility.Vector3dVector(pcd_points)\n",
    "        pcd.colors = o3d.utility.Vector3dVector(pcd_colors)\n",
    "        vis.add_geometry(pcd)\n",
    "    pcd.points = o3d.utility.Vector3dVector(pcd_points) #Only need XYZ\n",
    "    pcd.colors = o3d.utility.Vector3dVector(pcd_colors)\n",
    "    #vis.clear_geometries()\n",
    "    #vis.add_geometry(pcd)\n",
    "\n",
    "    # Update the visualization window and process events to handle keyboard inputs.\n",
    "    vis.update_geometry(pcd)\n",
    "    vis.poll_events()\n",
    "    vis.update_renderer()\n",
    "\n",
    "    #Next Sample\n",
    "    sample = nusc.get('sample', sample['next'])\n",
    "\n",
    "    #Slow down animation\n",
    "    time.sleep(0.25)\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "# Create an Open3D visualization window.\n",
    "vis = o3d.visualization.VisualizerWithKeyCallback()\n",
    "\n",
    "# Set the custom update function.\n",
    "vis.register_animation_callback(render_callback)\n",
    "\n",
    "\n",
    "# Start animation.\n",
    "vis.create_window()\n",
    "\n",
    "opt = vis.get_render_option()\n",
    "opt.background_color = np.asarray([0, 0, 0])\n",
    "opt.point_size = 2.5 #Original 5\n",
    "\n",
    "vis.run()\n",
    "vis.destroy_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_points =np.empty((3, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.append(pcd_points, np.array([[1, 1], [2, 2], [3, 3] ]), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIDAR 2 IMG Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load lidar and img data from scan\n",
    "sample = first_sample\n",
    "cam_channel = 'CAM_FRONT_RIGHT'\n",
    "#Load camera image\n",
    "cam = nusc.get('sample_data', sample['data'][cam_channel])\n",
    "cam_file = os.path.join(nusc.dataroot, cam['filename'])\n",
    "cam_img = cv2.imread(cam_file)\n",
    "\n",
    "#Load lidar scan\n",
    "lidar = nusc.get('sample_data', sample['data']['LIDAR_TOP'])\n",
    "lidar_file = nusc.get_sample_data_path(lidar['token'])\n",
    "scan = np.fromfile(lidar_file, dtype=np.float32).reshape(-1, 5) #x, y, z, intensity, Ring Index\n",
    "points = scan[:, :3] #Only x, y, z\n",
    "\n",
    "#Get Lidar Pose\n",
    "lidar_sensor = nusc.get('calibrated_sensor', lidar['calibrated_sensor_token'])\n",
    "lidar_t = np.asarray(lidar_sensor['translation'])\n",
    "lidar_r_quat = Quaternion(lidar_sensor['rotation'])\n",
    "\n",
    "#Get Camera Pose and intrinsic parameters\n",
    "cam_sensor = nusc.get('calibrated_sensor', cam['calibrated_sensor_token'])\n",
    "cam_t = np.asarray(cam_sensor['translation'])\n",
    "cam_r_quat = Quaternion(cam_sensor['rotation'])\n",
    "cam_k = np.asarray(cam_sensor['camera_intrinsic'])\n",
    "\n",
    "#Transform points to image frame - Using Open3D transformations\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(points)\n",
    "\n",
    "#First transformation\n",
    "pcd.rotate(lidar_r_quat.rotation_matrix, np.array([0, 0, 0]))\n",
    "pcd.translate(lidar_t)\n",
    "\n",
    "#Second transformation\n",
    "pcd.translate(-cam_t)\n",
    "pcd.rotate(cam_r_quat.rotation_matrix.T, np.array([0, 0, 0]))\n",
    "\n",
    "#Project points into image plane\n",
    "view = np.copy(cam_k)\n",
    "points = np.asarray(pcd.points).T[:3, :]\n",
    "\n",
    "#Set color to depth value\n",
    "depth = points[2, :]\n",
    "\n",
    "#Prepare intrinsics matrix for homogenous transformation\n",
    "viewpad = np.eye(4)\n",
    "viewpad[:view.shape[0], :view.shape[1]] = view\n",
    "\n",
    "#Prepare points for homogenous transformation\n",
    "points = np.concatenate((points, np.ones((1, points.shape[1])))) #4 X N matrix - Homogenous\n",
    "\n",
    "#Project Points into image\n",
    "points = np.dot(viewpad, points)\n",
    "\n",
    "#Remove w\n",
    "points = points[:3, :]\n",
    "\n",
    "#Normalize along Z axis - Divide by depth\n",
    "points = points / points[2, :]\n",
    "\n",
    "# Remove points that are either outside or behind the camera. Leave a margin of 1 pixel for aesthetic reasons.\n",
    "# Also make sure points are at least 1m in front of the camera to avoid seeing the lidar points on the camera\n",
    "# casing for non-keyframes which are slightly out of sync.\n",
    "min_dist = 1.0\n",
    "mask = np.ones(points.shape[1], dtype=bool)\n",
    "mask = np.logical_and(mask, depth > min_dist)\n",
    "mask = np.logical_and(mask, points[0, :] > 1)\n",
    "mask = np.logical_and(mask, points[0, :] < cam_img.shape[1] - 1)#cv image has x axis on dimension 1\n",
    "mask = np.logical_and(mask, points[1, :] > 1)\n",
    "mask = np.logical_and(mask, points[1, :] < cam_img.shape[0] - 1)\n",
    "points_img = np.uint8(np.rint(points))[:2, mask] #The x, y coordinates of the points that lie in the image\n",
    "points = points[:, mask]\n",
    "\n",
    "#Extract color values from image\n",
    "pts_color = np.zeros((points.shape[1], 3))\n",
    "for i in range(points.shape[1]):\n",
    "    pts_color[i] = cam_img[int(np.rint(points[1, i])), int(np.rint(points[0, i]))]\n",
    "#pts_color = (pts_color - pts_color.min()) / (pts_color.max() - pts_color.min()) #Normalize to range 0 to 1\n",
    "\n",
    "#BGR to RGB\n",
    "pts_color = pts_color[:, ::-1]\n",
    "pts_color = pts_color.astype(np.float32) / 255.0\n",
    "\n",
    "pcd_points = scan[mask, :3]\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(pcd_points) #Nx3 #pcd_points\n",
    "pcd.colors = o3d.utility.Vector3dVector(pts_color) #Nx3\n",
    "\n",
    "#o3d.visualization.draw_geometries([pcd])\n",
    "custom_draw_geometry(pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load lidar scan\n",
    "lidar = nusc.get('sample_data', sample['data']['LIDAR_TOP'])\n",
    "lidar_file = nusc.get_sample_data_path(lidar['token'])\n",
    "scan = np.fromfile(lidar_file, dtype=np.float32).reshape(-1, 5) #x, y, z, intensity, Ring Index\n",
    "pcd_points = scan[:, :3] #Only x, y, z\n",
    "\n",
    "#pcd_points = scan[mask, :3]\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(pcd_points) #Nx3 #pcd_points\n",
    "#pcd.colors = o3d.utility.Vector3dVector(pts_color) #Nx3\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd])\n",
    "#custom_draw_geometry(pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "winname = cam['channel']\n",
    "window_width, window_height = 800, 600\n",
    "cv2.namedWindow(winname, cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(winname, window_width, window_height)\n",
    "\n",
    "cv2.imshow(winname, cam_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('output_image.jpg', cam_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fusion1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

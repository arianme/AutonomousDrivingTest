{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-mini...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "911 instance,\n",
      "12 sensor,\n",
      "120 calibrated_sensor,\n",
      "31206 ego_pose,\n",
      "8 log,\n",
      "10 scene,\n",
      "404 sample,\n",
      "31206 sample_data,\n",
      "18538 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 0.466 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 0.1 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.transforms import functional as F\n",
    "from PIL import Image\n",
    "\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "import nuscenes.lidarseg\n",
    "from nuscenes.utils.data_classes import LidarPointCloud, RadarPointCloud, Box\n",
    "import utils_obj_det\n",
    "from utils_obj_det import get_radar_in_img, vis_obj_det_speed\n",
    "import utils_data_viewer\n",
    "from utils_data_viewer import radar_from_file, fuse_radars_in_ego, visualize_radar_in_img\n",
    "\n",
    "\n",
    "import time\n",
    "from scipy.spatial.transform import Rotation\n",
    "from pyquaternion import Quaternion\n",
    "\n",
    "import cv2\n",
    "#import open3d as o3d\n",
    "\n",
    "\n",
    "nusc = NuScenes(version='v1.0-mini', dataroot='/data/sets/nuscenes', verbose=True)\n",
    "utils_obj_det.nusc = nusc\n",
    "utils_data_viewer.nusc = nusc\n",
    "#nusc.list_scenes()\n",
    "sc_id = 4\n",
    "\n",
    "scene = nusc.scene[sc_id]\n",
    "log = nusc.get('log', scene['log_token'])\n",
    "map = nusc.get('map', log['map_token'])\n",
    "map_file = os.path.join(nusc.dataroot, map['filename'])\n",
    "\n",
    "first_sample = nusc.get('sample', scene['first_sample_token'])\n",
    "last_sample = nusc.get('sample', scene['last_sample_token'])\n",
    "sample = first_sample\n",
    "\n",
    "\t\n",
    "COCO_INSTANCE_CATEGORY_NAMES = ['__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table', 'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show Radar extracted speed for objects in camera view\n",
    "vis_obj_det_speed(scene, \"CAM_FRONT\", record=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model.eval()\n",
    "model.to('cuda')\n",
    "\n",
    "cam = nusc.get('sample_data', sample['data']['CAM_FRONT'])\n",
    "cam_file = os.path.join(nusc.dataroot, cam['filename'])\n",
    "cam_img = cv2.imread(cam_file)\n",
    "#Change to RGB only for conversion to tensor\n",
    "cam_tensor = F.to_tensor(cv2.cvtColor(cam_img, cv2.COLOR_BGR2RGB)).unsqueeze(0).to('cuda')\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    pred = model(cam_tensor)\n",
    "\n",
    "threshold = 0.9\n",
    "\n",
    "\n",
    "pred_class = [COCO_INSTANCE_CATEGORY_NAMES[i] for i in list(pred[0]['labels'].cpu().numpy())]\n",
    "pred_boxes = [[(i[0], i[1]), (i[2], i[3])] for i in list(pred[0]['boxes'].cpu().detach().numpy().astype(int))]\n",
    "pred_score = list(pred[0]['scores'].cpu().detach().numpy())\n",
    "#Find last index which belongs to score bigger than threshold\n",
    "pred_t = [pred_score.index(x) for x in pred_score if x>threshold][-1]\n",
    "pred_boxes = pred_boxes[:pred_t+1]\n",
    "pred_class = pred_class[:pred_t+1]\n",
    "results = np.copy(cam_img)\n",
    "\n",
    "rect_th=1\n",
    "text_size=1\n",
    "text_th=1\n",
    "\n",
    "\n",
    "#Draw bounding boxes\n",
    "for i in range(len(pred_boxes)):\n",
    "    cv2.rectangle(results, pred_boxes[i][0], pred_boxes[i][1], color=(0, 255, 0), thickness=rect_th)\n",
    "    cv2.putText(results, pred_class[i], pred_boxes[i][0], cv2.FONT_HERSHEY_SIMPLEX, text_size, (0,255,0),thickness=text_th)\n",
    "\n",
    "winname = cam['channel']\n",
    "window_width, window_height = 800, 600\n",
    "cv2.namedWindow(winname, cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(winname, window_width, window_height)\n",
    "\n",
    "cv2.imshow(winname, results)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pred = model(cam_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fusion1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
